{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKzEgMwWvSlX",
    "tags": []
   },
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install torcheval onnx wandb kaggle --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22670,
     "status": "ok",
     "timestamp": 1682103386777,
     "user": {
      "displayName": "Yuanqi Wang",
      "userId": "08153049365085382306"
     },
     "user_tz": 240
    },
    "id": "S9wvDvKJs_lf",
    "outputId": "1a3cccfd-5834-4c24-f864-211d96382365",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, WeightedRandomSampler\n",
    "import torch.optim as optim\n",
    "from torcheval.metrics.functional import multiclass_f1_score\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Download data if not found\n",
    "### *You should upload kaggle.json to the current working dir before running this cell*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"Data\"):\n",
    "    !mkdir -p ~/.kaggle\n",
    "    !mv kaggle.json ~/.kaggle/\n",
    "    !ls ~/.kaggle\n",
    "    !chmod 600 ~/.kaggle/kaggle.json  # set permission\n",
    "    !kaggle competitions download -c cassava-leaf-disease-classification -p ./\n",
    "    !mkdir Data\n",
    "    !unzip -q -n cassava-leaf-disease-classification.zip -d ./Data\n",
    "    !rm cassava-leaf-disease-classification.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Wandb Setup\n",
    "### *Change the env below to be your notebook path, also follow the prompt to enter your wandb token*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "executionInfo": {
     "elapsed": 26873,
     "status": "ok",
     "timestamp": 1682103782062,
     "user": {
      "displayName": "Yuanqi Wang",
      "userId": "08153049365085382306"
     },
     "user_tz": 240
    },
    "id": "xj6lDb5ktynW",
    "outputId": "b546d108-9bcf-4185-b853-55a8bb05d63c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtonghuovo\u001b[0m (\u001b[33mcassava\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['WANDB_NOTEBOOK_NAME'] = \"LinearRegression.ipynb\"\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UWM9Gk8FwHKy",
    "tags": []
   },
   "source": [
    "# *Define Customized Dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 121,
     "status": "ok",
     "timestamp": 1682104037476,
     "user": {
      "displayName": "Yuanqi Wang",
      "userId": "08153049365085382306"
     },
     "user_tz": 240
    },
    "id": "fBOyn5Q6wL_E",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LeafDataset(Dataset):\n",
    "    def __init__(self, root_path, transform=None):\n",
    "        self.image_path = root_path + '/train_images'\n",
    "        self.labels = pd.read_csv(root_path + '/train.csv')\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.image_path, self.labels['image_id'][idx])\n",
    "        image = Image.open(img_name)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if \"label\" in self.labels.columns:\n",
    "            label = self.labels['label'][idx]\n",
    "            sample = (image, label)\n",
    "        else:\n",
    "            sample = (image)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDe6wYc5y4OX",
    "tags": []
   },
   "source": [
    "# Define Torch Module\n",
    "### *Change this to your own model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 137,
     "status": "ok",
     "timestamp": 1682104072491,
     "user": {
      "displayName": "Yuanqi Wang",
      "userId": "08153049365085382306"
     },
     "user_tz": 240
    },
    "id": "-6gs5NQIy7WH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SoftmaxRegression(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        super().__init__()\n",
    "        # Create the layers of CNN\n",
    "        self.linear = nn.Linear(n_inputs, n_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Perform the forward pass through the layers\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pi-7R6wouO4O",
    "tags": []
   },
   "source": [
    "# Define Run Segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujflJvR2zyDg",
    "tags": []
   },
   "source": [
    "## The Whole Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1682104131291,
     "user": {
      "displayName": "Yuanqi Wang",
      "userId": "08153049365085382306"
     },
     "user_tz": 240
    },
    "id": "Qo8x6gBHz0wk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_pipeline(hyperparameters):\n",
    "    # tell wandb to get started\n",
    "    with wandb.init(project=\"cassava-leaf\", config=hyperparameters):\n",
    "        # access all HPs through wandb.config, so logging matches execution!\n",
    "        config = wandb.config\n",
    "\n",
    "        # make the model, data, and optimization problem\n",
    "        model, train_loader, eval_loader, test_loader, criterion, optimizer = make(config)\n",
    "        print(model)\n",
    "\n",
    "        # and use them to train the model\n",
    "        train(model, train_loader, eval_loader, criterion, optimizer, config)\n",
    "\n",
    "        # and test its final performance\n",
    "        test(model, test_loader)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJ-wOqgUuxQC",
    "tags": []
   },
   "source": [
    "## 1. Make (Model, loaders...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWuvahfV13qH",
    "tags": []
   },
   "source": [
    "### Helper functions for Make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 106,
     "status": "ok",
     "timestamp": 1682107712003,
     "user": {
      "displayName": "Yuanqi Wang",
      "userId": "08153049365085382306"
     },
     "user_tz": 240
    },
    "id": "ccDJ_GUB13H5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_datasets(split, transform):\n",
    "    total_dataset = LeafDataset('./Data', transform=transform)\n",
    "    subsets = random_split(total_dataset,\n",
    "                           split,\n",
    "                           generator=torch.Generator().manual_seed(42))\n",
    "    return subsets\n",
    "\n",
    "\n",
    "def make_loaders(datasets, batch_size, num_workers, balance=False):\n",
    "    if balance:\n",
    "        # compute class weights:\n",
    "        class_weights = [0] * 5\n",
    "        for _, label in datasets[0]:\n",
    "            class_weights[label] += 1\n",
    "        class_weights = [10000 / i for i in class_weights]\n",
    "\n",
    "        # compute sample weights\n",
    "        sample_weights = [0] * len(datasets[0])\n",
    "        for idx, (data, label) in enumerate(datasets[0]):\n",
    "            sample_weights[idx] = class_weights[label]\n",
    "        # init weighted sampler\n",
    "        sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "        train_dataloader = DataLoader(datasets[0], batch_size=batch_size, num_workers=num_workers, sampler=sampler)\n",
    "    else:\n",
    "        train_dataloader = DataLoader(datasets[0], batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    eval_dataloader = DataLoader(datasets[1], batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    test_dataloader = DataLoader(datasets[2], batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    return train_dataloader, eval_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PqN4oa1j2N4V"
   },
   "source": [
    "### Make main function (Adjust Transforms / Model Declaration Here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1682104309645,
     "user": {
      "displayName": "Yuanqi Wang",
      "userId": "08153049365085382306"
     },
     "user_tz": 240
    },
    "id": "zaYbg_m_t9H9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make(config):\n",
    "    trans_list = [\n",
    "        transforms.Resize((config.resize, config.resize))\n",
    "    ]\n",
    "    if config.flip is not None:\n",
    "        trans_list.append(transforms.RandomHorizontalFlip(0.3))\n",
    "        trans_list.append(transforms.RandomVerticalFlip(0.3))\n",
    "    trans_list.append(transforms.ToTensor())\n",
    "    trans_list.append(transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]))\n",
    "    transform = transforms.Compose(trans_list)\n",
    "\n",
    "    # Make the data\n",
    "    datasets = get_datasets(config.split, transform)\n",
    "    train_loader, eval_loader, test_loader = make_loaders(datasets,\n",
    "                                                          batch_size=config.batch_size,\n",
    "                                                          num_workers=config.num_workers,\n",
    "                                                          balance=config.balance)\n",
    "\n",
    "    # Make the model\n",
    "    model = SoftmaxRegression(3 * config.resize * config.resize, 5)\n",
    "    model.cuda()\n",
    "\n",
    "    # Make the loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(),\n",
    "                            lr=config.learning_rate,\n",
    "                            weight_decay=config.weight_decay)\n",
    "    return model, train_loader, eval_loader, test_loader, criterion, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_WC26SB3P9L",
    "tags": []
   },
   "source": [
    "## 2. Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jekrw3Em3dWP"
   },
   "source": [
    "### Helper functions for Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 103,
     "status": "ok",
     "timestamp": 1682104310361,
     "user": {
      "displayName": "Yuanqi Wang",
      "userId": "08153049365085382306"
     },
     "user_tz": 240
    },
    "id": "H8m-MIR44AlI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.\n",
    "    correct, total = 0, 0\n",
    "    for _, (images, labels) in enumerate(train_loader):\n",
    "        # move data\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        # forward prop\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # backward prop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # record performance\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc = correct / total\n",
    "    return train_loss, train_acc\n",
    "\n",
    "\n",
    "def eval_epoch(model, eval_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.\n",
    "    correct, total = 0, 0\n",
    "    for _, (images, labels) in enumerate(eval_loader):\n",
    "        # move data\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        # forward prop\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # record performance\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    eval_loss = running_loss / len(eval_loader)\n",
    "    eval_acc = correct / total\n",
    "    return eval_loss, eval_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7R0IL804NwQ"
   },
   "source": [
    "### Train main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1682104310469,
     "user": {
      "displayName": "Yuanqi Wang",
      "userId": "08153049365085382306"
     },
     "user_tz": 240
    },
    "id": "YL1sIMJR4Qh0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, eval_loader, criterion, optimizer, config):\n",
    "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
    "    for epoch in range(config.epochs):\n",
    "\n",
    "        # train model\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
    "        # evaluate model\n",
    "        eval_loss, eval_acc = eval_epoch(model, eval_loader, criterion)\n",
    "\n",
    "        # log to wandb\n",
    "        wandb.log({\"train_loss\": train_loss,\n",
    "                   \"train_acc\": train_acc,\n",
    "                   \"eval_loss\": eval_loss,\n",
    "                   \"eval_acc\": eval_acc}, step=epoch)\n",
    "        print(f\"Epoch {epoch}: Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.3f}, Eval Loss: {eval_loss:.3f}, Eval Acc: {eval_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_YPp6vZwAYMv",
    "tags": []
   },
   "source": [
    "## 3. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 122,
     "status": "ok",
     "timestamp": 1682110233133,
     "user": {
      "displayName": "Yuanqi Wang",
      "userId": "08153049365085382306"
     },
     "user_tz": 240
    },
    "id": "T2ct4sERAlNx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "\n",
    "    # Run the model on some test examples\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        label_total = torch.tensor([])\n",
    "        pred_total = torch.tensor([])\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            outputs = model(images)\n",
    "            # compute correct / total samples\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # concate labels\n",
    "            label_total = torch.cat((label_total, labels.detach().cpu()), dim=0)\n",
    "            pred_total = torch.cat((pred_total, predicted.detach().cpu()), dim=0)\n",
    "        # compute accuracy\n",
    "        acc = correct / total\n",
    "        wandb.log({\"test_accuracy\": acc})\n",
    "        # compute f1 scores\n",
    "        pred_total = pred_total.to(torch.int64)\n",
    "        label_total = label_total.to(torch.int64)\n",
    "        f1_micro = multiclass_f1_score(pred_total,\n",
    "                                       label_total,\n",
    "                                       num_classes=5,\n",
    "                                       average=\"micro\")\n",
    "        f1_macro = multiclass_f1_score(pred_total,\n",
    "                                       label_total,\n",
    "                                       num_classes=5,\n",
    "                                       average=\"macro\")\n",
    "        f1_each = multiclass_f1_score(pred_total,\n",
    "                                      label_total,\n",
    "                                      num_classes=5,\n",
    "                                      average=None)\n",
    "        print(f\"Test Acc: {acc:.3f}, F1 micro: {f1_micro:.3f}, F1 macro: {f1_macro:.3f}, F1 each: {f1_each}\")\n",
    "        f1 = [[f\"f1_class_{idx}\", value] for idx, value in enumerate(f1_each)]\n",
    "        f1.append([\"f1_micro\", f1_micro])\n",
    "        f1.append([\"f1_macro\", f1_macro])\n",
    "        table = wandb.Table(data=f1, columns=[\"class\", \"f1_score\"])\n",
    "        wandb.log({\"my_bar_chart_1\": wandb.plot.bar(table, \"class\", \"f1_score\", title=\"F1 Score\")})\n",
    "\n",
    "        torch.save(model.state_dict(), \"model_state.pth\")\n",
    "        wandb.save(\"model_state.pth\")\n",
    "        torch.onnx.export(model, images, \"model.onnx\")\n",
    "        wandb.save(\"model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CI1bEp7AII3N",
    "tags": []
   },
   "source": [
    "# Run Pipeline\n",
    "# Define HyperParameters\n",
    "### *Change this according to your run, add config if needed*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649,
     "referenced_widgets": [
      "2faa1edef45b4a43a633c7df47bc895d",
      "d42499e402dc4a5a91de30ed17b8db4e",
      "78c9f7b627a84ac9a943769915ce3651",
      "b7a360f8750d4cd3bf70e692e19fd158",
      "67a543e9ea4d4399875536b1b7efec4a",
      "c9dc65596b424bd0980fb1c6ac4f6838",
      "f2d210cd60984143bf354b9d2096994a",
      "1e6d0079a1b0460f9cc64182945f0371"
     ]
    },
    "executionInfo": {
     "elapsed": 84218,
     "status": "ok",
     "timestamp": 1682110321463,
     "user": {
      "displayName": "Yuanqi Wang",
      "userId": "08153049365085382306"
     },
     "user_tz": 240
    },
    "id": "etATskXwIGUF",
    "outputId": "ffb05e5d-abf6-44a1-c6b4-5982b18fef30",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ec2-user/SageMaker/wandb/run-20230425_031137-ya48kban</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cassava/cassava-leaf/runs/ya48kban' target=\"_blank\">rare-lake-100</a></strong> to <a href='https://wandb.ai/cassava/cassava-leaf' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cassava/cassava-leaf' target=\"_blank\">https://wandb.ai/cassava/cassava-leaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cassava/cassava-leaf/runs/ya48kban' target=\"_blank\">https://wandb.ai/cassava/cassava-leaf/runs/ya48kban</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SoftmaxRegression(\n",
      "  (linear): Linear(in_features=12288, out_features=5, bias=True)\n",
      ")\n",
      "Epoch 0: Train Loss: 9.053, Train Acc: 0.250, Eval Loss: 4.908, Eval Acc: 0.184\n",
      "Epoch 1: Train Loss: 3.444, Train Acc: 0.293, Eval Loss: 4.567, Eval Acc: 0.209\n",
      "Epoch 2: Train Loss: 3.094, Train Acc: 0.302, Eval Loss: 3.176, Eval Acc: 0.259\n",
      "Epoch 3: Train Loss: 2.504, Train Acc: 0.329, Eval Loss: 3.406, Eval Acc: 0.178\n",
      "Epoch 4: Train Loss: 2.531, Train Acc: 0.334, Eval Loss: 2.771, Eval Acc: 0.222\n",
      "Epoch 5: Train Loss: 2.519, Train Acc: 0.345, Eval Loss: 1.913, Eval Acc: 0.349\n",
      "Epoch 6: Train Loss: 2.692, Train Acc: 0.335, Eval Loss: 2.237, Eval Acc: 0.449\n",
      "Epoch 7: Train Loss: 2.567, Train Acc: 0.350, Eval Loss: 2.397, Eval Acc: 0.361\n",
      "Epoch 8: Train Loss: 3.084, Train Acc: 0.322, Eval Loss: 2.814, Eval Acc: 0.273\n",
      "Epoch 9: Train Loss: 2.461, Train Acc: 0.347, Eval Loss: 2.459, Eval Acc: 0.384\n",
      "Test Acc: 0.387, F1 micro: 0.387, F1 macro: 0.218, F1 each: tensor([0.0996, 0.2050, 0.1238, 0.5731, 0.0873])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval_acc</td><td>▁▂▃▁▂▅█▆▃▆</td></tr><tr><td>eval_loss</td><td>█▇▄▄▃▁▂▂▃▂</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>train_acc</td><td>▁▄▅▇▇█▇█▆█</td></tr><tr><td>train_loss</td><td>█▂▂▁▁▁▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval_acc</td><td>0.38435</td></tr><tr><td>eval_loss</td><td>2.45902</td></tr><tr><td>test_accuracy</td><td>0.38689</td></tr><tr><td>train_acc</td><td>0.34654</td></tr><tr><td>train_loss</td><td>2.46137</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rare-lake-100</strong> at: <a href='https://wandb.ai/cassava/cassava-leaf/runs/ya48kban' target=\"_blank\">https://wandb.ai/cassava/cassava-leaf/runs/ya48kban</a><br/>Synced 6 W&B file(s), 1 media file(s), 1 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230425_031137-ya48kban/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eff835d3b1f415eb15ab1662ced7c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.0166691402499661, max=1.0))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ec2-user/SageMaker/wandb/run-20230425_032341-p3fln6hh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cassava/cassava-leaf/runs/p3fln6hh' target=\"_blank\">valiant-glade-101</a></strong> to <a href='https://wandb.ai/cassava/cassava-leaf' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cassava/cassava-leaf' target=\"_blank\">https://wandb.ai/cassava/cassava-leaf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cassava/cassava-leaf/runs/p3fln6hh' target=\"_blank\">https://wandb.ai/cassava/cassava-leaf/runs/p3fln6hh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SoftmaxRegression(\n",
      "  (linear): Linear(in_features=12288, out_features=5, bias=True)\n",
      ")\n",
      "Epoch 0: Train Loss: 13.815, Train Acc: 0.254, Eval Loss: 5.737, Eval Acc: 0.176\n",
      "Epoch 1: Train Loss: 2.946, Train Acc: 0.384, Eval Loss: 2.364, Eval Acc: 0.317\n",
      "Epoch 2: Train Loss: 1.857, Train Acc: 0.451, Eval Loss: 2.506, Eval Acc: 0.270\n",
      "Epoch 3: Train Loss: 1.630, Train Acc: 0.493, Eval Loss: 2.822, Eval Acc: 0.259\n",
      "Epoch 4: Train Loss: 1.664, Train Acc: 0.520, Eval Loss: 2.429, Eval Acc: 0.285\n",
      "Epoch 5: Train Loss: 2.099, Train Acc: 0.462, Eval Loss: 2.501, Eval Acc: 0.438\n",
      "Epoch 6: Train Loss: 1.835, Train Acc: 0.502, Eval Loss: 3.417, Eval Acc: 0.188\n",
      "Epoch 7: Train Loss: 1.381, Train Acc: 0.562, Eval Loss: 2.776, Eval Acc: 0.238\n",
      "Epoch 8: Train Loss: 1.787, Train Acc: 0.511, Eval Loss: 3.547, Eval Acc: 0.191\n",
      "Epoch 9: Train Loss: 1.366, Train Acc: 0.563, Eval Loss: 2.960, Eval Acc: 0.193\n",
      "Test Acc: 0.188, F1 micro: 0.188, F1 macro: 0.167, F1 each: tensor([0.0969, 0.1783, 0.1523, 0.2155, 0.1927])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval_acc</td><td>▁▅▃▃▄█▁▃▁▁</td></tr><tr><td>eval_loss</td><td>█▁▁▂▁▁▃▂▃▂</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▇▆▇█▇█</td></tr><tr><td>train_loss</td><td>█▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval_acc</td><td>0.19346</td></tr><tr><td>eval_loss</td><td>2.96005</td></tr><tr><td>test_accuracy</td><td>0.18754</td></tr><tr><td>train_acc</td><td>0.56257</td></tr><tr><td>train_loss</td><td>1.36585</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">valiant-glade-101</strong> at: <a href='https://wandb.ai/cassava/cassava-leaf/runs/p3fln6hh' target=\"_blank\">https://wandb.ai/cassava/cassava-leaf/runs/p3fln6hh</a><br/>Synced 6 W&B file(s), 1 media file(s), 1 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230425_032341-p3fln6hh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = dict(\n",
    "    model=\"LinearRegression\",\n",
    "    split=[0.4, 0.2, 0.4],  # train / val / test split ratio\n",
    "    batch_size=256,\n",
    "    resize=64,\n",
    "    num_workers=2,  # number of workers per dataloader\n",
    "    balance=True,  # weight balance train dataset\n",
    "    epochs=10,\n",
    "    learning_rate=0.01,\n",
    "    weight_decay=0.5,  # L2 regularization hyperparamter for Adam Optimizer\n",
    "    flip=0.3,\n",
    ")\n",
    "\n",
    "for flip in [0.3, None]:\n",
    "    config['flip'] = flip\n",
    "    for weight_decay in [0.01, 0.1, 0.5]:\n",
    "        config['weight_decay'] = weight_decay\n",
    "        for resize in [64, 128, 224]:\n",
    "            config['resize'] = resize\n",
    "            try:\n",
    "                model = model_pipeline(config)\n",
    "            except Exception as e:\n",
    "                print(f\"failed run on config: {config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM3shJxiYcqMSenvsCgujVu",
   "collapsed_sections": [
    "rNjpWNw9tpEm",
    "OjPUA9-JtuF8",
    "oKzEgMwWvSlX",
    "UWM9Gk8FwHKy",
    "LDe6wYc5y4OX",
    "USDGH9OBzWQF",
    "ujflJvR2zyDg",
    "IJ-wOqgUuxQC",
    "x_WC26SB3P9L"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1e6d0079a1b0460f9cc64182945f0371": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2faa1edef45b4a43a633c7df47bc895d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d42499e402dc4a5a91de30ed17b8db4e",
       "IPY_MODEL_78c9f7b627a84ac9a943769915ce3651"
      ],
      "layout": "IPY_MODEL_b7a360f8750d4cd3bf70e692e19fd158"
     }
    },
    "67a543e9ea4d4399875536b1b7efec4a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78c9f7b627a84ac9a943769915ce3651": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f2d210cd60984143bf354b9d2096994a",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1e6d0079a1b0460f9cc64182945f0371",
      "value": 0.9823056694606827
     }
    },
    "b7a360f8750d4cd3bf70e692e19fd158": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9dc65596b424bd0980fb1c6ac4f6838": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d42499e402dc4a5a91de30ed17b8db4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_67a543e9ea4d4399875536b1b7efec4a",
      "placeholder": "​",
      "style": "IPY_MODEL_c9dc65596b424bd0980fb1c6ac4f6838",
      "value": "0.471 MB of 0.480 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "f2d210cd60984143bf354b9d2096994a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
